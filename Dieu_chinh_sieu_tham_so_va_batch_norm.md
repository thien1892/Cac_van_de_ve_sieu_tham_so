# Các siêu tham số:
1. Learning rate anpha
2. Beta (khi sử dụng trung bình động gradient descent)
3. mini-batch size
4. Hidden units ?
5. Layer?
6. Learning rate decay
7. ADAM: beta1 = 0.9, beta2 = 0.999, epsilon = 10^-8  
**Việc ưu tiên điều chỉnh siêu tham số theo thứ tự 1 --> (2,3,4) --> (5,6). Và ít khi điều chỉnh các siêu tham số khi sử dụng ADAM**


